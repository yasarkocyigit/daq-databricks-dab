# Databricks Apps configuration for Builder App
# Copy this file to app.yaml and customize for your deployment
#
# Prerequisites:
#   1. Create the app: databricks apps create <your-app-name>
#   2. Add Lakebase as a resource (see instructions below)
#   3. Configure your LLM provider settings

command:
  - "uvicorn"
  - "server.app:app"
  - "--host"
  - "0.0.0.0"
  - "--port"
  - "$DATABRICKS_APP_PORT"

env:
  # =============================================================================
  # Application Settings
  # =============================================================================
  - name: ENV
    value: "production"
  - name: PROJECTS_BASE_DIR
    value: "./projects"
  - name: PYTHONPATH
    value: "/app/python/source_code/packages"
  
  # =============================================================================
  # Skills Configuration
  # =============================================================================
  # Comma-separated list of skills to enable
  - name: ENABLED_SKILLS
    value: "databricks-spark-declarative-pipelines,databricks-asset-bundles,databricks-jobs,databricks-unity-catalog,databricks-python-sdk"
  - name: SKILLS_ONLY_MODE
    value: "false"
  
  # =============================================================================
  # Database Configuration (Lakebase)
  # =============================================================================
  # IMPORTANT: You must add Lakebase as an app resource for database connectivity.
  # 
  # Steps:
  #   1. Create a Lakebase instance in your workspace (if not exists)
  #   2. Add it as an app resource (Databricks CLI v0.289+):
  #      databricks apps update <app-name> --json '{
  #        "resources": [{
  #          "name": "lakebase",
  #          "database": {
  #            "instance_name": "<your-lakebase-instance-name>",
  #            "database_name": "databricks_postgres",
  #            "permission": "CAN_CONNECT_AND_CREATE"
  #          }
  #        }]
  #      }'
  #
  # When added as a resource, Databricks automatically sets:
  #   - PGHOST, PGPORT, PGUSER, PGPASSWORD, PGDATABASE
  #
  # You only need to specify the instance name for OAuth token generation:
  - name: LAKEBASE_INSTANCE_NAME
    value: "<your-lakebase-instance-name>"
  - name: LAKEBASE_DATABASE_NAME
    value: "databricks_postgres"
  
  # =============================================================================
  # LLM Provider Configuration
  # =============================================================================
  # Option 1: Databricks Foundation Models (default)
  - name: LLM_PROVIDER
    value: "DATABRICKS"
  - name: DATABRICKS_MODEL
    value: "databricks-meta-llama-3-3-70b-instruct"
  - name: DATABRICKS_MODEL_MINI
    value: "databricks-gemini-3-flash"
  
  # Option 2: Anthropic Claude (uncomment and add your key)
  # - name: ANTHROPIC_API_KEY
  #   value: "<your-anthropic-api-key>"
  
  # Option 3: Azure OpenAI (uncomment and configure)
  # - name: LLM_PROVIDER
  #   value: "AZURE"
  # - name: AZURE_OPENAI_API_KEY
  #   value: "<your-azure-api-key>"
  # - name: AZURE_OPENAI_ENDPOINT
  #   value: "https://<your-resource>.cognitiveservices.azure.com/"
  # - name: AZURE_OPENAI_API_VERSION
  #   value: "2024-08-01-preview"
  # - name: AZURE_OPENAI_DEPLOYMENT
  #   value: "gpt-4o"
  # - name: AZURE_OPENAI_DEPLOYMENT_MINI
  #   value: "gpt-4o-mini"
  
  # =============================================================================
  # Claude SDK Configuration (Databricks FMAPI)
  # =============================================================================
  # These configure the Claude Agent SDK to use Databricks model serving endpoints
  # instead of hitting Anthropic directly. The app dynamically sets ANTHROPIC_BASE_URL
  # and ANTHROPIC_AUTH_TOKEN from the user's Databricks credentials at runtime.
  - name: ANTHROPIC_MODEL
    value: "databricks-claude-sonnet-4-5"
  - name: ANTHROPIC_MODEL_MINI
    value: "databricks-claude-sonnet-4-5"
  - name: CLAUDE_CODE_STREAM_CLOSE_TIMEOUT
    value: "3600000"

  # =============================================================================
  # MLflow Tracing Configuration
  # =============================================================================
  # Enable MLflow tracing for Claude Code conversations
  # Traces are automatically sent to your Databricks workspace
  # See: https://docs.databricks.com/aws/en/mlflow3/genai/tracing/integrations/claude-code
  - name: MLFLOW_CLAUDE_TRACING_ENABLED
    value: "true"
  - name: MLFLOW_TRACKING_URI
    value: "databricks"

  # =============================================================================
  # Permission Configuration
  # =============================================================================
  # Grant created resources to this principal (e.g., "account users" for all)
  - name: AUTO_GRANT_PERMISSIONS_TO
    value: "account users"
